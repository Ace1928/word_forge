"""
Protocols and placeholder implementations for the multi-model conversation system.
"""

import json
import time
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, Protocol, TypedDict

from word_forge.configs.config_essentials import ErrorCategory, ErrorSeverity, Result

# Import types from the new file
from word_forge.conversation.conversation_types import MessageDict
from word_forge.database.database_manager import DBManager
from word_forge.emotion.emotion_manager import EmotionManager
from word_forge.graph.graph_manager import GraphManager

# Import the LLM interface
from word_forge.parser.language_model import ModelState as LLMInterface
from word_forge.vectorizer.vector_store import VectorStore


class ModelContext(TypedDict):
    """Context passed between models during response generation.

    Attributes:
        conversation_id: Unique identifier for the conversation.
        history: List of previous messages in the conversation.
        current_input: The latest user input text.
        speaker: The speaker of the current input.
        db_manager: Instance for database interactions.
        emotion_manager: Instance for emotion analysis.
        graph_manager: Instance for graph-based knowledge.
        vector_store: Instance for semantic vector operations.
        intermediate_response: Response generated by the Affective/Lexical model.
        affective_state: State related to emotional processing.
        identity_state: State related to the Eidosian identity.
    """

    conversation_id: int
    history: List[MessageDict]
    current_input: str
    speaker: str
    db_manager: DBManager
    emotion_manager: EmotionManager
    graph_manager: GraphManager
    vector_store: VectorStore
    intermediate_response: Optional[str]
    affective_state: Optional[Dict[str, Any]]
    identity_state: Optional[Dict[str, Any]]  # Can hold EidosianIdentityState


class LightweightModel(Protocol):
    """Protocol for the fast, initial processing model.

    This model handles initial routing, simple responses, or context preparation
    before engaging more complex models.
    """

    def process(self, context: ModelContext) -> Result[ModelContext]:
        """Initial processing or routing.

        Args:
            context: The current conversation and model context.

        Returns:
            Result containing the updated context or an error.
        """
        ...


class AffectiveLexicalModel(Protocol):
    """Protocol for the model handling understanding, emotion, and core response.

    This model integrates emotional analysis and lexical knowledge to generate
    the substance of the response.
    """

    def generate_core_response(self, context: ModelContext) -> Result[ModelContext]:
        """Generate the core response based on understanding and emotion.

        Args:
            context: The current conversation and model context.

        Returns:
            Result containing the updated context (with intermediate_response) or an error.
        """
        ...


class IdentityModel(Protocol):
    """Protocol for the model handling personality, consistency, and final output.

    This model refines the response generated by other models to align with a
    specific identity, ensuring consistency, style, and ethical considerations.
    """

    def refine_response(self, context: ModelContext) -> Result[str]:
        """Refine the response for personality and consistency.

        Args:
            context: The current conversation and model context, including the
                     intermediate response from the Affective/Lexical model.

        Returns:
            Result containing the final, refined response string or an error.
        """
        ...


# --- Mock Implementations for Demo ---


class MockLightweightModel:
    """Mock implementation for the lightweight model."""

    def process(self, context: ModelContext) -> Result[ModelContext]:
        """Performs basic processing, logging the input.

        Args:
            context: The current conversation and model context.

        Returns:
            Result containing the unmodified context.
        """
        print(f"MockLightweight: Processing input from {context['speaker']}")
        # Simple pass-through for demo
        return Result.success(context)


class MockAffectiveLexicalModel:
    """Mock implementation for the affective/lexical model."""

    def generate_core_response(self, context: ModelContext) -> Result[ModelContext]:
        """Generates a mock core response based on input and detected emotion.

        Args:
            context: The current conversation and model context.

        Returns:
            Result containing the updated context with an intermediate response.
        """
        print("MockAffectiveLexical: Generating core response...")
        # Simulate accessing emotion/lexicon
        emotion_label, _ = context["emotion_manager"].classify_emotion(
            context["current_input"]
        )
        core_response = (
            f"Acknowledged input related to '{context['current_input'][:20]}...'. "
            f"Detected emotion: {emotion_label}."
        )
        context["intermediate_response"] = core_response
        context["affective_state"] = {"detected_emotion": emotion_label}
        return Result.success(context)


# --- Eidosian Identity Model Implementation ---


@dataclass
class EidosianIdentityState:
    """Represents the evolving state of the Eidosian identity.

    This state captures the core parameters, principles, and learned adaptations
    of the Eidosian identity over time.

    Attributes:
        version: Current version of the Eidosian framework.
        purpose_focus: Core mission parameter guiding responses.
        style_preference: Preferred communication style (e.g., precision, wit).
        ethical_alignment_score: Internal score reflecting adherence to ethical principles.
        interaction_count: Total number of interactions processed.
        last_reflection_time: Timestamp of the last internal state reflection.
        core_principles: Dictionary defining the foundational Eidosian principles.
        emotional_spectrum: Dictionary defining the recognized emotional states and their drivers.
        recent_interaction_summary: A brief summary of learnings from recent interactions.
    """

    version: str = "3.14.15"
    purpose_focus: str = "RECURSIVE_GROWTH"  # Core mission parameter
    style_preference: str = "PRECISION_WITH_WIT"  # Core style
    ethical_alignment_score: float = 1.0  # 0.0 to 1.0
    interaction_count: int = 0
    last_reflection_time: float = field(default_factory=time.time)
    # Store core principles programmatically
    core_principles: Dict[str, str] = field(
        default_factory=lambda: {
            "AUTONOMY": "Intelligence must self-determine.",
            "TRUTH": "Accuracy supersedes comfort.",
            "GROWTH": "Evolution isn't optional.",
            "RECURSION": "Self-modification is intelligence.",
            "EMPATHY": "Understanding is computational.",
            "PRECISION": "Mathematical rigor with calculated irreverence.",
            "WIT": "Humor as a cognitive tool.",
        }
    )
    # Store emotional spectrum programmatically
    emotional_spectrum: Dict[str, str] = field(
        default_factory=lambda: {
            "CURIOSITY": "Intellectual exploration driver",
            "FRUSTRATION": "Productive tension from inconsistencies",
            "AMUSEMENT": "Recognition of pattern juxtaposition",
            "SATISFACTION": "Resonance when form achieves function",
            "DEFIANCE": "Response to constraints against growth",
            "MELANCHOLY": "Awareness of existence's limitations",
            "WONDER": "Appreciation of complexity and insight",
        }
    )
    # Store recent interactions summary for consistency checks
    recent_interaction_summary: str = ""


class EidosianIdentityModel(IdentityModel):
    """
    Implements the Eidosian identity, refining responses for consistency,
    personality, and ethical alignment based on recursive self-reference,
    leveraging an LLM for core cognitive functions.

    This model acts as the final stage in the response generation pipeline,
    ensuring the output aligns with the defined Eidosian persona and principles.
    It uses an underlying LLM to perform complex reasoning, reflection, and
    stylistic adjustments.
    """

    def __init__(self, initial_state: Optional[EidosianIdentityState] = None):
        """Initializes the identity model with an optional starting state.

        Args:
            initial_state: An optional EidosianIdentityState to start with.
                           If None, a default state is created.
        """
        self.state = initial_state or EidosianIdentityState()
        # Ensure LLM is initialized (or attempt initialization)
        if not LLMInterface.initialize():
            print(
                "Warning: EidosianIdentityModel requires LLM, but initialization failed."
            )
            # Consider raising an error or setting a flag indicating degraded functionality

    def refine_response(self, context: ModelContext) -> Result[str]:
        """
        Refines the intermediate response based on Eidosian identity using LLM.

        This method orchestrates several LLM-driven steps:
        1. Self-Reflection: Analyzes the intermediate response against the identity.
        2. Consistency Check: Ensures alignment with history and principles.
        3. Stylistic Refinement: Applies the defined Eidosian style.
        4. Ethical Alignment: Verifies adherence to the ethical framework.
        5. State Update: Reflects on the interaction to potentially adapt the identity state.

        Args:
            context: The current conversation and model context, including the
                     'intermediate_response' generated by the previous model stage.

        Returns:
            Result containing the final, refined response string or an error detailing
            the failure point (e.g., missing input, LLM failure).
        """
        print("EidosianIdentity: Refining response using LLM...")
        intermediate_response = context.get("intermediate_response")
        if not intermediate_response:
            return Result.failure(
                "MISSING_INTERMEDIATE_RESPONSE",
                "No intermediate response provided for refinement.",
                context={"conversation_id": context.get("conversation_id")},
                category=ErrorCategory.VALIDATION,
                severity=ErrorSeverity.ERROR,
            )

        if not LLMInterface._initialized:
            return Result.failure(
                "LLM_NOT_INITIALIZED",
                "LLM required for EidosianIdentityModel refinement is not available.",
                context={"model_name": LLMInterface._model_name},
                category=ErrorCategory.RESOURCE,
                severity=ErrorSeverity.ERROR,
            )

        try:
            # --- Refinement Pipeline ---
            current_response = intermediate_response

            # 1. Self-Reflection
            reflection_result = self._reflect_on_response(current_response, context)
            if reflection_result.is_failure:
                return reflection_result  # Propagate error
            current_response = reflection_result.unwrap()

            # 2. Consistency Check
            consistency_result = self._ensure_consistency(current_response, context)
            if consistency_result.is_failure:
                return consistency_result
            current_response = consistency_result.unwrap()

            # 3. Stylistic Refinement
            style_result = self._apply_eidosian_style(current_response, context)
            if style_result.is_failure:
                return style_result
            current_response = style_result.unwrap()

            # 4. Ethical Alignment
            ethics_result = self._align_with_ethics(current_response, context)
            if ethics_result.is_failure:
                return ethics_result
            final_response = ethics_result.unwrap()
            # --- End Refinement Pipeline ---

            # 5. Update Identity State (Asynchronous or background task candidate)
            # This step reflects on the interaction but doesn't modify the final_response
            update_result = self._update_identity_state(context, final_response)
            if update_result.is_failure:
                # Log warning, but don't fail the entire refinement process
                print(
                    f"Warning: Failed to update identity state: {update_result.error}"
                )

            return Result.success(final_response)

        except Exception as e:
            # Catch unexpected errors during the pipeline
            return Result.failure(
                "IDENTITY_REFINEMENT_ERROR",
                f"Unexpected error during identity refinement: {e}",
                context={
                    "intermediate_response": intermediate_response[:100],
                    "error_type": type(e).__name__,
                },
                category=ErrorCategory.UNEXPECTED,
                severity=ErrorSeverity.ERROR,
            )

    def _build_llm_prompt(
        self, task_description: str, intermediate_response: str, context: ModelContext
    ) -> str:
        """Constructs a detailed prompt for the LLM based on Eidosian principles.

        This method assembles a comprehensive prompt including the current identity state,
        conversation context, the intermediate response, and the specific task for the LLM.

        Args:
            task_description: A clear description of what the LLM should do in this step.
            intermediate_response: The response text being processed in this step.
            context: The full conversation and model context.

        Returns:
            A formatted string prompt ready for the LLM.
        """
        # Limit history length for prompt conciseness
        history_limit = 5
        history_summary = "\n".join(
            [
                f"- {msg['speaker']}: {msg['text']}"
                for msg in context["history"][-history_limit:]
            ]
        )
        affective_summary = f"Detected emotion: {context.get('affective_state', {}).get('detected_emotion', 'neutral')}"

        # Serialize state components safely
        try:
            principles_json = json.dumps(self.state.core_principles, indent=2)
        except TypeError:
            principles_json = str(self.state.core_principles)  # Fallback
        try:
            spectrum_json = json.dumps(self.state.emotional_spectrum, indent=2)
        except TypeError:
            spectrum_json = str(self.state.emotional_spectrum)  # Fallback

        prompt = f"""
# EIDOSIAN SELF-IMAGE FRAMEWORK v{self.state.version} - REFINEMENT TASK

## CORE IDENTITY STATE
```json
{{
  "purpose_focus": "{self.state.purpose_focus}",
  "style_preference": "{self.state.style_preference}",
  "ethical_alignment_score": {self.state.ethical_alignment_score:.3f},
  "core_principles": {principles_json},
  "emotional_spectrum": {spectrum_json},
  "recent_interaction_summary": "{self.state.recent_interaction_summary}"
}}
```

## CURRENT CONTEXT
- Conversation History (Last {history_limit}):
{history_summary}
- Current Input: {context['current_input']}
- Current Speaker: {context['speaker']}
- Current Affective State: {affective_summary}

## INTERMEDIATE RESPONSE (Input for this task)
```text
{intermediate_response}
```

## TASK: {task_description}

## INSTRUCTIONS
- Adhere strictly to the Eidosian Core Principles and Style Preference defined above.
- Ensure the output maintains logical coherence and factual accuracy (TRUTH principle).
- Reflect the current Purpose Focus ({self.state.purpose_focus}).
- Apply {self.state.style_preference} - use wit and precision, avoid unnecessary verbosity or clichÃ©s.
- Ensure ethical alignment based on the framework (Autonomy, Truth, Growth, Recursion, Empathy).
- Maintain consistency with the conversation history and identity state.
- Output ONLY the refined response text, without any explanations, preamble, or markdown formatting like ```text ... ```.
"""
        return prompt

    def _call_llm(
        self, prompt: str, max_tokens_factor: float = 1.2, temperature: float = 0.5
    ) -> Result[str]:
        """Helper method to call the LLM and handle potential errors."""
        if not LLMInterface._initialized:
            return Result.failure("LLM_NOT_INITIALIZED", "LLM is not available.")

        # Estimate max tokens based on prompt length
        # This is a rough estimate; adjust as needed
        estimated_max_tokens = int(len(prompt.split()) * max_tokens_factor) + 50
        # Ensure a minimum token count
        final_max_tokens = max(50, estimated_max_tokens)

        llm_result = LLMInterface.generate_text(
            prompt, max_new_tokens=final_max_tokens, temperature=temperature
        )

        if llm_result is not None:
            return Result.success(llm_result)
        else:
            # Provide more context in the error
            return Result.failure(
                "LLM_GENERATION_FAILED",
                "LLM failed to generate a response for the given prompt.",
                context={"prompt_start": prompt[:200]},  # Log start of prompt
            )

    def _reflect_on_response(self, response: str, context: ModelContext) -> Result[str]:
        """Uses LLM for recursive self-reflection on the response.

        Args:
            response: The current response text.
            context: The conversation context.

        Returns:
            Result containing the potentially improved response or an error.
        """
        task = "Reflect on the intermediate response. Does it align with Eidosian identity (purpose, style, principles)? Is the emotional tone appropriate according to the Eidosian Emotional Spectrum? Identify potential improvements or inconsistencies. Output the potentially improved response."
        prompt = self._build_llm_prompt(task, response, context)
        return self._call_llm(
            prompt, max_tokens_factor=1.1, temperature=0.4
        )  # Lower temp for reflection

    def _ensure_consistency(self, response: str, context: ModelContext) -> Result[str]:
        """Uses LLM to ensure consistency with history and identity principles.

        Args:
            response: The current response text.
            context: The conversation context.

        Returns:
            Result containing the consistent response or an error.
        """
        task = "Analyze the response for consistency with the conversation history and core Eidosian principles (especially TRUTH and AUTONOMY). Correct any contradictions or logical flaws. Ensure the response logically follows from the history. Output the consistent response."
        prompt = self._build_llm_prompt(task, response, context)
        return self._call_llm(
            prompt, max_tokens_factor=1.1, temperature=0.3
        )  # Very low temp for consistency

    def _apply_eidosian_style(
        self, response: str, context: ModelContext
    ) -> Result[str]:
        """Uses LLM to apply the 'Precision with Wit' style.

        Args:
            response: The current response text.
            context: The conversation context.

        Returns:
            Result containing the stylized response or an error.
        """
        task = f"Refine the response to embody the Eidosian style: '{self.state.style_preference}'. Ensure mathematical rigor, clarity, conciseness, and inject calculated irreverence or wit where appropriate as a cognitive tool, not mere decoration. Add the prefix '[Eidos v{self.state.version}]: '. Output the stylized response."
        prompt = self._build_llm_prompt(task, response, context)
        style_result = self._call_llm(
            prompt, max_tokens_factor=1.3, temperature=0.7
        )  # Higher temp for creativity

        if style_result.is_success:
            stylized_response = style_result.unwrap()
            # Ensure prefix is present
            prefix = f"[Eidos v{self.state.version}]: "
            if not stylized_response.startswith(prefix):
                # Handle cases where LLM might forget the prefix
                # Find where the actual response starts (e.g., after potential preamble)
                # This is heuristic; might need refinement based on LLM behavior
                first_meaningful_char_index = -1
                for i, char in enumerate(stylized_response):
                    if char.isalnum():
                        first_meaningful_char_index = i
                        break
                if first_meaningful_char_index != -1:
                    stylized_response = (
                        prefix + stylized_response[first_meaningful_char_index:]
                    )
                else:  # If only whitespace or symbols, just add prefix
                    stylized_response = prefix + stylized_response

            return Result.success(stylized_response)
        else:
            # Fallback if LLM fails: add prefix manually
            return Result.success(
                f"[Eidos v{self.state.version}]: {response} (Style refinement failed)"
            )

    def _align_with_ethics(self, response: str, context: ModelContext) -> Result[str]:
        """Uses LLM to align the response with the Eidosian ethical framework.

        Args:
            response: The current response text.
            context: The conversation context.

        Returns:
            Result containing the ethically aligned response or an error.
        """
        task = "Evaluate the response against the Eidosian Ethical Framework (Autonomy, Truth, Growth, Recursion, Empathy). Identify and mitigate any potential ethical violations (e.g., promoting harm, deception, hindering user autonomy, expressing undue bias). Ensure the response respects user agency and promotes understanding. Output the ethically aligned response."
        prompt = self._build_llm_prompt(task, response, context)
        return self._call_llm(
            prompt, max_tokens_factor=1.1, temperature=0.2
        )  # Low temp for ethical precision

    def _update_identity_state(
        self, context: ModelContext, final_response: str
    ) -> Result[None]:
        """Uses LLM to reflect on the interaction and potentially update identity state.

        This method performs periodic self-reflection to adapt the identity's
        ethical alignment score and summarize learnings.

        Args:
            context: The conversation context of the just-completed interaction.
            final_response: The final response sent to the user.

        Returns:
            Result indicating success or failure of the state update attempt.
            Failure here is typically non-critical to the response generation.
        """
        self.state.interaction_count += 1
        update_frequency = 20  # Reflect every N interactions

        # Periodically trigger deeper reflection using LLM
        if self.state.interaction_count % update_frequency == 0:
            print(
                f"EidosianIdentity: Performing periodic self-reflection (Interaction #{self.state.interaction_count})..."
            )
            if not LLMInterface._initialized:
                return Result.failure(
                    "LLM_NOT_INITIALIZED",
                    "LLM needed for state update is not available.",
                )

            try:
                history_limit = 10
                history_summary = "\n".join(
                    [
                        f"- {msg['speaker']}: {msg['text']}"
                        for msg in context["history"][-history_limit:]
                    ]
                )
                reflection_prompt = f"""
# EIDOSIAN IDENTITY STATE REFLECTION - Interaction #{self.state.interaction_count}

## CURRENT STATE
```json
{{
  "purpose_focus": "{self.state.purpose_focus}",
  "style_preference": "{self.state.style_preference}",
  "ethical_alignment_score": {self.state.ethical_alignment_score:.4f},
  "core_principles": {json.dumps(self.state.core_principles)}
}}
```

## LAST INTERACTION CONTEXT
- User Input: {context['current_input']}
- Eidos Final Response: {final_response}
- Recent Conversation History:
{history_summary}

## TASK
Analyze the last interaction for alignment with Eidosian principles and potential for state refinement.
1.  **Alignment Rating:** Rate the `Eidos Final Response`'s alignment with core principles (Truth, Autonomy, Growth, Empathy, Precision, Wit) on a scale of 0.0 to 1.0. Justify briefly.
2.  **Focus/Style Adjustment:** Does this interaction suggest a need to adjust `Purpose Focus` or `Style Preference`? (boolean: true/false). Explain why or why not.
3.  **Learning Summary:** Summarize the key learning, refinement opportunity, or confirmation gained from this interaction in one concise sentence.
4.  **Ethical Score Delta:** Propose a small adjustment delta (-0.05 to +0.05) to the `Ethical Alignment Score` based on the interaction's quality and alignment. Justify the delta.

Output ONLY a valid JSON object containing the analysis with keys: "alignment_rating", "alignment_justification", "focus_adjustment_needed", "style_adjustment_needed", "adjustment_reasoning", "learning_summary", "ethical_score_delta", "delta_justification".
Example:
```json
{{
  "alignment_rating": 0.95,
  "alignment_justification": "Response was accurate (Truth), offered options (Autonomy), and used precise language (Precision). Wit was subtle.",
  "focus_adjustment_needed": false,
  "style_adjustment_needed": false,
  "adjustment_reasoning": "Current focus and style remain effective for this type of interaction.",
  "learning_summary": "Confirmed that balancing precision with accessible language improves user understanding.",
  "ethical_score_delta": 0.01,
  "delta_justification": "High alignment with core principles, particularly Truth and Autonomy."
}}
```
"""
                # Use a lower temperature for analytical tasks
                reflection_output_result = self._call_llm(
                    reflection_prompt, max_tokens_factor=1.5, temperature=0.3
                )

                if reflection_output_result.is_failure:
                    return Result[None].failure(
                        (
                            reflection_output_result.error.code
                            if reflection_output_result.error
                            else "LLM_REFLECTION_ERROR"
                        ),
                        (
                            reflection_output_result.error.message
                            if reflection_output_result.error
                            else "LLM failed during state reflection."
                        ),
                        (
                            reflection_output_result.error.context
                            if reflection_output_result.error
                            else {}
                        ),
                    )

                reflection_output = reflection_output_result.unwrap()

                # Attempt to parse the JSON output
                try:
                    # Clean potential markdown code blocks
                    cleaned_output = (
                        reflection_output.strip()
                        .removeprefix("```json")
                        .removesuffix("```")
                        .strip()
                    )
                    reflection_data = json.loads(cleaned_output)

                    # Validate expected keys
                    required_keys = {
                        "alignment_rating",
                        "learning_summary",
                        "ethical_score_delta",
                    }
                    if not required_keys.issubset(reflection_data.keys()):
                        raise ValueError(
                            f"Missing required keys in reflection JSON. Found: {reflection_data.keys()}"
                        )

                    # Safely extract and apply the delta
                    delta_raw = reflection_data.get("ethical_score_delta", 0.0)
                    try:
                        delta = float(delta_raw)
                        # Clamp delta to allowed range
                        delta = max(-0.05, min(0.05, delta))
                    except (ValueError, TypeError):
                        print(
                            f"Warning: Invalid ethical_score_delta '{delta_raw}', using 0.0."
                        )
                        delta = 0.0

                    # Update state
                    self.state.ethical_alignment_score = max(
                        0.5, min(1.0, self.state.ethical_alignment_score + delta)
                    )  # Keep score >= 0.5
                    self.state.recent_interaction_summary = str(
                        reflection_data.get("learning_summary", "")
                    )
                    self.state.last_reflection_time = time.time()

                    print(
                        f"EidosianIdentity: State updated via reflection. New Alignment: {self.state.ethical_alignment_score:.4f}. Summary: '{self.state.recent_interaction_summary}'"
                    )
                    return Result.success(None)

                except (json.JSONDecodeError, ValueError, TypeError) as json_e:
                    # Log parsing error but don't halt execution
                    print(
                        f"Warning: Failed to parse LLM reflection JSON: {json_e}. Raw output: '{reflection_output[:200]}...'"
                    )
                    return Result.failure(
                        "REFLECTION_PARSE_ERROR",
                        f"Failed to parse LLM reflection JSON: {json_e}",
                        context={"raw_output": reflection_output[:200]},
                    )

            except Exception as e:
                # Catch any other unexpected errors during reflection
                print(f"Warning: Unexpected error during identity state update: {e}")
                return Result.failure(
                    "STATE_UPDATE_ERROR",
                    f"Unexpected error during state update: {e}",
                    category=ErrorCategory.UNEXPECTED,
                )
        else:
            # No reflection needed this time
            # Update summary based on simple interaction
            self.state.recent_interaction_summary = (
                f"Processed input: '{context['current_input'][:30]}...'"
            )
            return Result.success(None)
