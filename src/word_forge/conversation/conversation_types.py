"""
Type definitions for conversation management structures.

This module centralizes the core data structures used for representing
conversations and messages within the Word Forge system, ensuring
type consistency across different components like the manager, models,
and workers.
"""

from typing import Any, Dict, List, Optional, Protocol, TypedDict

# Import Result from config_essentials
from word_forge.configs.config_essentials import Result
from word_forge.database.database_manager import DBManager
from word_forge.emotion.emotion_manager import EmotionManager
from word_forge.emotion.emotion_types import EmotionAnalysisDict
from word_forge.graph.graph_manager import GraphManager
from word_forge.vectorizer.vector_store import VectorStore


class MessageDict(TypedDict):
    """
    Represents a single message within a conversation.

    Attributes:
        id: Unique identifier for the message.
        speaker: Identifier of the entity sending the message (e.g., "User", "Assistant").
        text: The textual content of the message.
        timestamp: Unix timestamp indicating when the message was recorded.
        emotion: Optional analysis of the message's emotional content.
    """

    id: int
    speaker: str
    text: str
    timestamp: float
    emotion: Optional[EmotionAnalysisDict]


class ConversationDict(TypedDict):
    """
    Represents a complete conversation session.

    Attributes:
        id: Unique identifier for the conversation.
        status: Current status of the conversation (e.g., "ACTIVE", "COMPLETED").
        created_at: Unix timestamp when the conversation was initiated.
        updated_at: Unix timestamp of the last activity in the conversation.
        messages: Chronological list of messages constituting the conversation.
    """

    id: int
    status: str
    created_at: float
    updated_at: float
    messages: List[MessageDict]


class ModelContext(TypedDict, total=False):
    """
    Shared context passed between conversation models during processing.

    This dictionary acts as a blackboard, allowing different models in the
    pipeline to access shared information and contribute intermediate results.

    Attributes:
        conversation_id: Identifier of the current conversation.
        history: List of recent messages for context.
        current_input: The latest user message being processed.
        speaker: The speaker of the current input message.
        db_manager: Instance for database access.
        emotion_manager: Instance for emotion analysis and access.
        graph_manager: Instance for accessing the knowledge graph.
        vector_store: Instance for vector-based similarity searches.
        reflexive_output: Output from the initial ReflexiveModel.
        intermediate_response: Response generated by the core AffectiveLexicalModel.
        affective_state: State or analysis produced by the AffectiveLexicalModel.
        identity_state: Current state or parameters of the IdentityModel.
        additional_data: Any other relevant data models might need or produce.
    """

    conversation_id: int
    history: List[MessageDict]
    current_input: str
    speaker: str
    db_manager: DBManager
    emotion_manager: EmotionManager
    graph_manager: GraphManager
    vector_store: VectorStore
    reflexive_output: Optional[Any]  # Output from ReflexiveModel
    intermediate_response: Optional[str]  # Output from AffectiveLexicalModel
    affective_state: Optional[Dict[str, Any]]  # State from AffectiveLexicalModel
    identity_state: Optional[Dict[str, Any]]  # State related to IdentityModel
    additional_data: Dict[str, Any]


# Define Protocols for the models based on their expected methods
class ReflexiveModel(Protocol):
    """Protocol for the initial, fast reflexive response model."""

    def generate_reflex(self, context: ModelContext) -> Result[ModelContext]:
        """
        Generates a quick initial response or context update.

        Args:
            context: The current conversation context.

        Returns:
            Result containing the updated context or an error.
        """
        ...


class LightweightModel(Protocol):
    """Protocol for the routing and basic processing model."""

    def process(self, context: ModelContext) -> Result[ModelContext]:
        """
        Processes the context, potentially routing or performing basic tasks.

        Args:
            context: The current conversation context, potentially updated by ReflexiveModel.

        Returns:
            Result containing the updated context or an error.
        """
        ...


class AffectiveLexicalModel(Protocol):
    """Protocol for the core understanding and response generation model."""

    def generate_core_response(self, context: ModelContext) -> Result[ModelContext]:
        """
        Generates the main response based on deep understanding.

        Args:
            context: The current conversation context, potentially updated by previous models.

        Returns:
            Result containing the updated context (with intermediate_response) or an error.
        """
        ...


class IdentityModel(Protocol):
    """Protocol for the personality, consistency, and refinement model."""

    def refine_response(self, context: ModelContext) -> Result[str]:
        """
        Refines the intermediate response based on identity and consistency.

        Args:
            context: The current conversation context, containing the intermediate_response.

        Returns:
            Result containing the final response string or an error.
        """
        ...


__all__ = [
    "MessageDict",
    "ConversationDict",
    "ModelContext",
    "ReflexiveModel",
    "LightweightModel",
    "AffectiveLexicalModel",
    "IdentityModel",
]
